{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import getLoadersMap\n",
    "from models import UNetMultiDate\n",
    "\n",
    "import os, logging, phobos\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from phobos.grain import Grain\n",
    "from phobos.runner import Runner\n",
    "\n",
    "from polyaxon.tracking import Run\n",
    "\n",
    "from phobos.loss import save_loss_map\n",
    "from phobos.metrics import save_metrics_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not local testing\n"
     ]
    }
   ],
   "source": [
    "if not Runner.local_testing():\n",
    "    print('not local testing')\n",
    "    experiment = Run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Grain(yaml='metadata.yaml',polyaxon_exp=experiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, outputs = args.get_inputs_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(args.weight_dir):\n",
    "    os.makedirs(args.weight_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_loss_map('maps')\n",
    "#save_metrics_map('maps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train keys : 9170\n",
      "number of val keys : 4610\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loaders = getLoadersMap(args,inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tloader = loaders['train']\n",
    "#for inputs, labels in tloader:\n",
    "#    print(inputs['inp1'].shape)\n",
    "#    print(labels['out1'].shape,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = inputs.heads['inp1'].shape.H\n",
    "device = torch.device(\"cuda\",0)\n",
    "n_channels = inputs.heads['inp1'].shape.C\n",
    "\n",
    "n_classes  = outputs.heads['out1'].num_classes\n",
    "if n_classes == 2:\n",
    "    n_classes = 1\n",
    "\n",
    "if args.model == 'unetmultidate':\n",
    "    model = args.load_model(UNetMultiDate,\n",
    "                                n_channels=n_channels,\n",
    "                                n_classes=n_classes,\n",
    "                                patch_size=shape,\n",
    "                                device=device\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.distributed:\n",
    "    model = nn.parallel.DistributedDataParallel(model, find_unused_parameters=False)\n",
    "elif args.num_gpus > 1:\n",
    "    model = nn.DataParallel(model, device_ids=list(range(args.num_gpus)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.pretrained_checkpoint:\n",
    "    \"\"\"\n",
    "    If you have any pretrained weights that you want to load for the model, this \n",
    "    is the place to do it.\n",
    "    \"\"\"\n",
    "    print(f'pretrained checkpoint set to {args.pretrained_checkpoint}')\n",
    "    pretrained = torch.load(args.pretrained_checkpoint)\n",
    "    model.load_state_dict(pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.resume_checkpoint:\n",
    "    \"\"\"If we want to resume training from some checkpoints.\n",
    "    \"\"\"\n",
    "    print(f'pretrained checkpoint set to {args.pretrained_checkpoint}')\n",
    "    weight = torch.load(args.resume_checkpoint)\n",
    "    model.load_state_dict(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = Runner(\n",
    "    model=model,\n",
    "    device=args.device,\n",
    "    train_loader=loaders['train'],\n",
    "    val_loader=loaders['val'], \n",
    "    inputs=inputs, \n",
    "    outputs=outputs, \n",
    "    optimizer=args.optimizer, \n",
    "    optimizer_args=args.optimizer_args,\n",
    "    scheduler=args.scheduler,\n",
    "    scheduler_args=args.scheduler_args,\n",
    "    mode=args.mode,\n",
    "    distributed=args.distributed,\n",
    "    verbose=args.verbose,\n",
    "    max_iters=args.max_iters,\n",
    "    frequency=args.frequency, \n",
    "    tensorboard_logging=True, \n",
    "    polyaxon_exp=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.5010952353477478\n",
      "\t\trecall: 0.501265287399292\n",
      "\t\tf1: 0.500917375087738\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.6563423871994019\n",
      "\ttrain_loss : 0.6563423871994019\n",
      "train_loss: 0.6563423871994019\n",
      "step: 2\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.5026018619537354\n",
      "\t\trecall: 0.5012729167938232\n",
      "\t\tf1: 0.4971616864204407\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.6359084844589233\n",
      "\ttrain_loss : 0.6359084844589233\n",
      "train_loss: 0.6359084844589233\n",
      "step: 3\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.5021465420722961\n",
      "\t\trecall: 0.5008498430252075\n",
      "\t\tf1: 0.49551260471343994\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.616326093673706\n",
      "\ttrain_loss : 0.616326093673706\n",
      "train_loss: 0.616326093673706\n",
      "step: 4\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.48958638310432434\n",
      "\t\trecall: 0.49746468663215637\n",
      "\t\tf1: 0.4887101352214813\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.5959136486053467\n",
      "\ttrain_loss : 0.5959136486053467\n",
      "train_loss: 0.5959136486053467\n",
      "step: 5\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.5046526789665222\n",
      "\t\trecall: 0.5007055997848511\n",
      "\t\tf1: 0.4908607304096222\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.5798969268798828\n",
      "\ttrain_loss : 0.5798969268798828\n",
      "train_loss: 0.5798969268798828\n",
      "step: 6\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4871395528316498\n",
      "\t\trecall: 0.4992451071739197\n",
      "\t\tf1: 0.48192933201789856\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.5706852078437805\n",
      "\ttrain_loss : 0.5706852078437805\n",
      "train_loss: 0.5706852078437805\n",
      "step: 7\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.527506411075592\n",
      "\t\trecall: 0.500841498374939\n",
      "\t\tf1: 0.478841096162796\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.5676563382148743\n",
      "\ttrain_loss : 0.5676563382148743\n",
      "train_loss: 0.5676563382148743\n",
      "step: 8\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.521586000919342\n",
      "\t\trecall: 0.5008834004402161\n",
      "\t\tf1: 0.48967668414115906\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.5407021045684814\n",
      "\ttrain_loss : 0.5407021045684814\n",
      "train_loss: 0.5407021045684814\n",
      "step: 9\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.48489266633987427\n",
      "\t\trecall: 0.4997548758983612\n",
      "\t\tf1: 0.482838898897171\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.5374375581741333\n",
      "\ttrain_loss : 0.5374375581741333\n",
      "train_loss: 0.5374375581741333\n",
      "step: 10\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4682297706604004\n",
      "\t\trecall: 0.4997515082359314\n",
      "\t\tf1: 0.4834774136543274\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.5264225006103516\n",
      "\ttrain_loss : 0.5264225006103516\n",
      "train_loss: 0.5264225006103516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akash/anaconda3/envs/phobos/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "/home/akash/anaconda3/envs/phobos/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:378: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return [base_lr * self.gamma ** (self.last_epoch // self.step_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 10\n",
      "out1:\n",
      "\tval_metrics:\n",
      "\t\tprecision: 0.45655736327171326\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.47729218006134033\n",
      "\tval_loss:\n",
      "\t\tbcejaccardloss: 0.6178191304206848\n",
      "\tval_loss : 0.6178191304206848\n",
      "val_loss: 0.6178191304206848\n",
      "step: 11\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.457589715719223\n",
      "\t\trecall: 0.49982285499572754\n",
      "\t\tf1: 0.4777747690677643\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.5312828421592712\n",
      "\ttrain_loss : 0.5312828421592712\n",
      "train_loss: 0.5312828421592712\n",
      "step: 12\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.503704309463501\n",
      "\t\trecall: 0.5000105500221252\n",
      "\t\tf1: 0.47884076833724976\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.5247690677642822\n",
      "\ttrain_loss : 0.5247690677642822\n",
      "train_loss: 0.5247690677642822\n",
      "step: 13\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.529067873954773\n",
      "\t\trecall: 0.5000805258750916\n",
      "\t\tf1: 0.4822823405265808\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.510019063949585\n",
      "\ttrain_loss : 0.510019063949585\n",
      "train_loss: 0.510019063949585\n",
      "step: 14\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.45659664273262024\n",
      "\t\trecall: 0.49993106722831726\n",
      "\t\tf1: 0.47728225588798523\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.5151787996292114\n",
      "\ttrain_loss : 0.5151787996292114\n",
      "train_loss: 0.5151787996292114\n",
      "step: 15\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4543828070163727\n",
      "\t\trecall: 0.49996432662010193\n",
      "\t\tf1: 0.47608503699302673\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.5151783227920532\n",
      "\ttrain_loss : 0.5151783227920532\n",
      "train_loss: 0.5151783227920532\n",
      "step: 16\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4656510353088379\n",
      "\t\trecall: 0.4999774694442749\n",
      "\t\tf1: 0.4822041392326355\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.49402353167533875\n",
      "\ttrain_loss : 0.49402353167533875\n",
      "train_loss: 0.49402353167533875\n",
      "step: 17\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.9618489146232605\n",
      "\t\trecall: 0.5000500082969666\n",
      "\t\tf1: 0.48026779294013977\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.49564412236213684\n",
      "\ttrain_loss : 0.49564412236213684\n",
      "train_loss: 0.49564412236213684\n",
      "step: 18\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.46124032139778137\n",
      "\t\trecall: 0.49999380111694336\n",
      "\t\tf1: 0.4798358678817749\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4922090172767639\n",
      "\ttrain_loss : 0.4922090172767639\n",
      "train_loss: 0.4922090172767639\n",
      "step: 19\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4586772918701172\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4784480631351471\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.492878794670105\n",
      "\ttrain_loss : 0.492878794670105\n",
      "train_loss: 0.492878794670105\n",
      "step: 20\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.959457278251648\n",
      "\t\trecall: 0.5000235438346863\n",
      "\t\tf1: 0.47891905903816223\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.48988911509513855\n",
      "\ttrain_loss : 0.48988911509513855\n",
      "train_loss: 0.48988911509513855\n",
      "step: 20\n",
      "out1:\n",
      "\tval_metrics:\n",
      "\t\tprecision: 0.45655736327171326\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.47729218006134033\n",
      "\tval_loss:\n",
      "\t\tbcejaccardloss: 0.556891918182373\n",
      "\tval_loss : 0.556891918182373\n",
      "val_loss: 0.556891918182373\n",
      "step: 21\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4563215374946594\n",
      "\t\trecall: 0.49999791383743286\n",
      "\t\tf1: 0.47716233134269714\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.491291344165802\n",
      "\ttrain_loss : 0.491291344165802\n",
      "train_loss: 0.491291344165802\n",
      "step: 22\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4708546996116638\n",
      "\t\trecall: 0.49998176097869873\n",
      "\t\tf1: 0.4849812984466553\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.46604350209236145\n",
      "\ttrain_loss : 0.46604350209236145\n",
      "train_loss: 0.46604350209236145\n",
      "step: 23\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4714735746383667\n",
      "\t\trecall: 0.49999797344207764\n",
      "\t\tf1: 0.48531702160835266\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4608241617679596\n",
      "\ttrain_loss : 0.4608241617679596\n",
      "train_loss: 0.4608241617679596\n",
      "step: 24\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4669208526611328\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4828945994377136\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4650014042854309\n",
      "\ttrain_loss : 0.4650014042854309\n",
      "train_loss: 0.4650014042854309\n",
      "step: 25\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.46234703063964844\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48043692111968994\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.47106480598449707\n",
      "\ttrain_loss : 0.47106480598449707\n",
      "train_loss: 0.47106480598449707\n",
      "step: 26\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.9535366296768188\n",
      "\t\trecall: 0.5000410676002502\n",
      "\t\tf1: 0.4757183790206909\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4873427748680115\n",
      "\ttrain_loss : 0.4873427748680115\n",
      "train_loss: 0.4873427748680115\n",
      "step: 27\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.46356964111328125\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48109614849090576\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4657667875289917\n",
      "\ttrain_loss : 0.4657667875289917\n",
      "train_loss: 0.4657667875289917\n",
      "step: 28\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.46634864807128906\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48258841037750244\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.45759373903274536\n",
      "\ttrain_loss : 0.45759373903274536\n",
      "train_loss: 0.45759373903274536\n",
      "step: 29\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4767417907714844\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4880939722061157\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4353055953979492\n",
      "\ttrain_loss : 0.4353055953979492\n",
      "train_loss: 0.4353055953979492\n",
      "step: 30\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4650707244873047\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4819032549858093\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4571997821331024\n",
      "\ttrain_loss : 0.4571997821331024\n",
      "train_loss: 0.4571997821331024\n",
      "step: 30\n",
      "out1:\n",
      "\tval_metrics:\n",
      "\t\tprecision: 0.45655736327171326\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.47729218006134033\n",
      "\tval_loss:\n",
      "\t\tbcejaccardloss: 0.5113879442214966\n",
      "\tval_loss : 0.5113879442214966\n",
      "val_loss: 0.5113879442214966\n",
      "step: 31\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.47005653381347656\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4845661222934723\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.44461995363235474\n",
      "\ttrain_loss : 0.44461995363235474\n",
      "train_loss: 0.44461995363235474\n",
      "step: 32\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.45351600646972656\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4756249487400055\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.47759580612182617\n",
      "\ttrain_loss : 0.47759580612182617\n",
      "train_loss: 0.47759580612182617\n",
      "step: 33\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.46399879455566406\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4813271462917328\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4547460675239563\n",
      "\ttrain_loss : 0.4547460675239563\n",
      "train_loss: 0.4547460675239563\n",
      "step: 34\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4624652862548828\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4805007576942444\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4562285244464874\n",
      "\ttrain_loss : 0.4562285244464874\n",
      "train_loss: 0.4562285244464874\n",
      "step: 35\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4668865203857422\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4828762412071228\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.44595369696617126\n",
      "\ttrain_loss : 0.44595369696617126\n",
      "train_loss: 0.44595369696617126\n",
      "step: 36\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4592266082763672\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4787467420101166\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.46127942204475403\n",
      "\ttrain_loss : 0.46127942204475403\n",
      "train_loss: 0.46127942204475403\n",
      "step: 37\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.458099365234375\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4781334698200226\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4641883373260498\n",
      "\ttrain_loss : 0.4641883373260498\n",
      "train_loss: 0.4641883373260498\n",
      "step: 38\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4614391326904297\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4799462854862213\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.456146240234375\n",
      "\ttrain_loss : 0.456146240234375\n",
      "train_loss: 0.456146240234375\n",
      "step: 39\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.46129798889160156\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.47986993193626404\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.45344609022140503\n",
      "\ttrain_loss : 0.45344609022140503\n",
      "train_loss: 0.45344609022140503\n",
      "step: 40\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4606742858886719\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.47953224182128906\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4549255967140198\n",
      "\ttrain_loss : 0.4549255967140198\n",
      "train_loss: 0.4549255967140198\n",
      "step: 40\n",
      "out1:\n",
      "\tval_metrics:\n",
      "\t\tprecision: 0.45655736327171326\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.47729218006134033\n",
      "\tval_loss:\n",
      "\t\tbcejaccardloss: 0.48059892654418945\n",
      "\tval_loss : 0.48059892654418945\n",
      "val_loss: 0.48059892654418945\n",
      "step: 41\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4657726287841797\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48227980732917786\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4433287978172302\n",
      "\ttrain_loss : 0.4433287978172302\n",
      "train_loss: 0.4433287978172302\n",
      "step: 42\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4606475830078125\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.47951775789260864\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.45463478565216064\n",
      "\ttrain_loss : 0.45463478565216064\n",
      "train_loss: 0.45463478565216064\n",
      "step: 43\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.47008705139160156\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4845823347568512\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.43134698271751404\n",
      "\ttrain_loss : 0.43134698271751404\n",
      "train_loss: 0.43134698271751404\n",
      "step: 44\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4630928039550781\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48083922266960144\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.44620853662490845\n",
      "\ttrain_loss : 0.44620853662490845\n",
      "train_loss: 0.44620853662490845\n",
      "step: 45\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4751567840576172\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48726195096969604\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.41656482219696045\n",
      "\ttrain_loss : 0.41656482219696045\n",
      "train_loss: 0.41656482219696045\n",
      "step: 46\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4681415557861328\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48354658484458923\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.43313151597976685\n",
      "\ttrain_loss : 0.43313151597976685\n",
      "train_loss: 0.43313151597976685\n",
      "step: 47\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4623737335205078\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4804513156414032\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4483782649040222\n",
      "\ttrain_loss : 0.4483782649040222\n",
      "train_loss: 0.4483782649040222\n",
      "step: 48\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4647789001464844\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4817465543746948\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.44092077016830444\n",
      "\ttrain_loss : 0.44092077016830444\n",
      "train_loss: 0.44092077016830444\n",
      "step: 49\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.46979522705078125\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48442724347114563\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4268573522567749\n",
      "\ttrain_loss : 0.4268573522567749\n",
      "train_loss: 0.4268573522567749\n",
      "step: 50\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.47193336486816406\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48556143045425415\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4210464358329773\n",
      "\ttrain_loss : 0.4210464358329773\n",
      "train_loss: 0.4210464358329773\n",
      "step: 50\n",
      "out1:\n",
      "\tval_metrics:\n",
      "\t\tprecision: 0.45655736327171326\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.47729218006134033\n",
      "\tval_loss:\n",
      "\t\tbcejaccardloss: 0.46273186802864075\n",
      "\tval_loss : 0.46273186802864075\n",
      "val_loss: 0.46273186802864075\n",
      "step: 51\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4701423645019531\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48461171984672546\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4232875406742096\n",
      "\ttrain_loss : 0.4232875406742096\n",
      "train_loss: 0.4232875406742096\n",
      "step: 52\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4593524932861328\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.47881513833999634\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4492107033729553\n",
      "\ttrain_loss : 0.4492107033729553\n",
      "train_loss: 0.4492107033729553\n",
      "step: 53\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.46633148193359375\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48257920145988464\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4335210919380188\n",
      "\ttrain_loss : 0.4335210919380188\n",
      "train_loss: 0.4335210919380188\n",
      "step: 54\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.46117401123046875\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.47980281710624695\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4436072111129761\n",
      "\ttrain_loss : 0.4436072111129761\n",
      "train_loss: 0.4436072111129761\n",
      "step: 55\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.46597862243652344\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4823901951313019\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4331330955028534\n",
      "\ttrain_loss : 0.4331330955028534\n",
      "train_loss: 0.4331330955028534\n",
      "step: 56\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4708995819091797\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4850136935710907\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.42003706097602844\n",
      "\ttrain_loss : 0.42003706097602844\n",
      "train_loss: 0.42003706097602844\n",
      "step: 57\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4622955322265625\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4804091155529022\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.44262877106666565\n",
      "\ttrain_loss : 0.44262877106666565\n",
      "train_loss: 0.44262877106666565\n",
      "step: 58\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4635181427001953\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4810684025287628\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.438737154006958\n",
      "\ttrain_loss : 0.438737154006958\n",
      "train_loss: 0.438737154006958\n",
      "step: 59\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.45354461669921875\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4756406843662262\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4660930335521698\n",
      "\ttrain_loss : 0.4660930335521698\n",
      "train_loss: 0.4660930335521698\n",
      "step: 60\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4666595458984375\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48275479674339294\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4282994270324707\n",
      "\ttrain_loss : 0.4282994270324707\n",
      "train_loss: 0.4282994270324707\n",
      "step: 60\n",
      "out1:\n",
      "\tval_metrics:\n",
      "\t\tprecision: 0.45655736327171326\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.47729218006134033\n",
      "\tval_loss:\n",
      "\t\tbcejaccardloss: 0.4572434723377228\n",
      "\tval_loss : 0.4572434723377228\n",
      "val_loss: 0.4572434723377228\n",
      "step: 61\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.46693992614746094\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4829047918319702\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.42961376905441284\n",
      "\ttrain_loss : 0.42961376905441284\n",
      "train_loss: 0.42961376905441284\n",
      "step: 62\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4712848663330078\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48521795868873596\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4167388677597046\n",
      "\ttrain_loss : 0.4167388677597046\n",
      "train_loss: 0.4167388677597046\n",
      "step: 63\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4662952423095703\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48255980014801025\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.43033912777900696\n",
      "\ttrain_loss : 0.43033912777900696\n",
      "train_loss: 0.43033912777900696\n",
      "step: 64\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4723243713378906\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48576831817626953\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.41277146339416504\n",
      "\ttrain_loss : 0.41277146339416504\n",
      "train_loss: 0.41277146339416504\n",
      "step: 65\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.46044349670410156\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4794071614742279\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4428125023841858\n",
      "\ttrain_loss : 0.4428125023841858\n",
      "train_loss: 0.4428125023841858\n",
      "step: 66\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.46068763732910156\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4795394539833069\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.44213321805000305\n",
      "\ttrain_loss : 0.44213321805000305\n",
      "train_loss: 0.44213321805000305\n",
      "step: 67\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4657325744628906\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48225831985473633\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.42944782972335815\n",
      "\ttrain_loss : 0.42944782972335815\n",
      "train_loss: 0.42944782972335815\n",
      "step: 68\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.46625709533691406\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4825393855571747\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4299324154853821\n",
      "\ttrain_loss : 0.4299324154853821\n",
      "train_loss: 0.4299324154853821\n",
      "step: 69\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.45281219482421875\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4752376079559326\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4633796811103821\n",
      "\ttrain_loss : 0.4633796811103821\n",
      "train_loss: 0.4633796811103821\n",
      "step: 70\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4652862548828125\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48201894760131836\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4316699504852295\n",
      "\ttrain_loss : 0.4316699504852295\n",
      "train_loss: 0.4316699504852295\n",
      "step: 70\n",
      "out1:\n",
      "\tval_metrics:\n",
      "\t\tprecision: 0.45655736327171326\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.47729218006134033\n",
      "\tval_loss:\n",
      "\t\tbcejaccardloss: 0.4606214165687561\n",
      "\tval_loss : 0.4606214165687561\n",
      "val_loss: 0.4606214165687561\n",
      "step: 71\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.47248268127441406\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48585203289985657\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4098261594772339\n",
      "\ttrain_loss : 0.4098261594772339\n",
      "train_loss: 0.4098261594772339\n",
      "step: 72\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4644432067871094\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4815661609172821\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.43097081780433655\n",
      "\ttrain_loss : 0.43097081780433655\n",
      "train_loss: 0.43097081780433655\n",
      "step: 73\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.46967124938964844\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48436132073402405\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.41789761185646057\n",
      "\ttrain_loss : 0.41789761185646057\n",
      "train_loss: 0.41789761185646057\n",
      "step: 74\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.46318626403808594\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48088961839675903\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4355476498603821\n",
      "\ttrain_loss : 0.4355476498603821\n",
      "train_loss: 0.4355476498603821\n",
      "step: 75\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4625244140625\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4805326461791992\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.43880152702331543\n",
      "\ttrain_loss : 0.43880152702331543\n",
      "train_loss: 0.43880152702331543\n",
      "step: 76\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4510688781738281\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.47427570819854736\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.47011908888816833\n",
      "\ttrain_loss : 0.47011908888816833\n",
      "train_loss: 0.47011908888816833\n",
      "step: 77\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4734020233154297\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4863376319408417\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.40551984310150146\n",
      "\ttrain_loss : 0.40551984310150146\n",
      "train_loss: 0.40551984310150146\n",
      "step: 78\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.47132110595703125\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.485237181186676\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.41258037090301514\n",
      "\ttrain_loss : 0.41258037090301514\n",
      "train_loss: 0.41258037090301514\n",
      "step: 79\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4594306945800781\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4788576066493988\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4486355781555176\n",
      "\ttrain_loss : 0.4486355781555176\n",
      "train_loss: 0.4486355781555176\n",
      "step: 80\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4573345184326172\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4777165353298187\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4553256928920746\n",
      "\ttrain_loss : 0.4553256928920746\n",
      "train_loss: 0.4553256928920746\n",
      "step: 80\n",
      "out1:\n",
      "\tval_metrics:\n",
      "\t\tprecision: 0.45655736327171326\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.47729218006134033\n",
      "\tval_loss:\n",
      "\t\tbcejaccardloss: 0.4520052671432495\n",
      "\tval_loss : 0.4520052671432495\n",
      "val_loss: 0.4520052671432495\n",
      "step: 81\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4647216796875\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4817157983779907\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4279344081878662\n",
      "\ttrain_loss : 0.4279344081878662\n",
      "train_loss: 0.4279344081878662\n",
      "step: 82\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.46749114990234375\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48319941759109497\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.41956010460853577\n",
      "\ttrain_loss : 0.41956010460853577\n",
      "train_loss: 0.41956010460853577\n",
      "step: 83\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4661731719970703\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48249441385269165\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.42552268505096436\n",
      "\ttrain_loss : 0.42552268505096436\n",
      "train_loss: 0.42552268505096436\n",
      "step: 84\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4673786163330078\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4831392765045166\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4239822328090668\n",
      "\ttrain_loss : 0.4239822328090668\n",
      "train_loss: 0.4239822328090668\n",
      "step: 85\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4728889465332031\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4860667288303375\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.40615159273147583\n",
      "\ttrain_loss : 0.40615159273147583\n",
      "train_loss: 0.40615159273147583\n",
      "step: 86\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4671287536621094\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4830057621002197\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.42029082775115967\n",
      "\ttrain_loss : 0.42029082775115967\n",
      "train_loss: 0.42029082775115967\n",
      "step: 87\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4636859893798828\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4811587929725647\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4341775178909302\n",
      "\ttrain_loss : 0.4341775178909302\n",
      "train_loss: 0.4341775178909302\n",
      "step: 88\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.46155357360839844\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48000818490982056\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4393760561943054\n",
      "\ttrain_loss : 0.4393760561943054\n",
      "train_loss: 0.4393760561943054\n",
      "step: 89\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.45836448669433594\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4782778322696686\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4481104612350464\n",
      "\ttrain_loss : 0.4481104612350464\n",
      "train_loss: 0.4481104612350464\n",
      "step: 90\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4630146026611328\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48079708218574524\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4365287125110626\n",
      "\ttrain_loss : 0.4365287125110626\n",
      "train_loss: 0.4365287125110626\n",
      "step: 90\n",
      "out1:\n",
      "\tval_metrics:\n",
      "\t\tprecision: 0.45655736327171326\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.47729218006134033\n",
      "\tval_loss:\n",
      "\t\tbcejaccardloss: 0.4530663788318634\n",
      "\tval_loss : 0.4530663788318634\n",
      "val_loss: 0.4530663788318634\n",
      "step: 91\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4730682373046875\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48616141080856323\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4044065475463867\n",
      "\ttrain_loss : 0.4044065475463867\n",
      "train_loss: 0.4044065475463867\n",
      "step: 92\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4664459228515625\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48264047503471375\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4225720763206482\n",
      "\ttrain_loss : 0.4225720763206482\n",
      "train_loss: 0.4225720763206482\n",
      "step: 93\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4681987762451172\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4835771322250366\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.41708266735076904\n",
      "\ttrain_loss : 0.41708266735076904\n",
      "train_loss: 0.41708266735076904\n",
      "step: 94\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4715290069580078\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48534733057022095\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.40917903184890747\n",
      "\ttrain_loss : 0.40917903184890747\n",
      "train_loss: 0.40917903184890747\n",
      "step: 95\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4696063995361328\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4843268394470215\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4123274087905884\n",
      "\ttrain_loss : 0.4123274087905884\n",
      "train_loss: 0.4123274087905884\n",
      "step: 96\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4635028839111328\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4810602068901062\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.42935219407081604\n",
      "\ttrain_loss : 0.42935219407081604\n",
      "train_loss: 0.42935219407081604\n",
      "step: 97\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4616737365722656\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48007315397262573\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4404797852039337\n",
      "\ttrain_loss : 0.4404797852039337\n",
      "train_loss: 0.4404797852039337\n",
      "step: 98\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.450836181640625\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4741470515727997\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.47393691539764404\n",
      "\ttrain_loss : 0.47393691539764404\n",
      "train_loss: 0.47393691539764404\n",
      "step: 99\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4703712463378906\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4847332835197449\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4121825695037842\n",
      "\ttrain_loss : 0.4121825695037842\n",
      "train_loss: 0.4121825695037842\n",
      "step: 100\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4628734588623047\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48072096705436707\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.43604224920272827\n",
      "\ttrain_loss : 0.43604224920272827\n",
      "train_loss: 0.43604224920272827\n",
      "step: 100\n",
      "out1:\n",
      "\tval_metrics:\n",
      "\t\tprecision: 0.45655736327171326\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.47729218006134033\n",
      "\tval_loss:\n",
      "\t\tbcejaccardloss: 0.4533294141292572\n",
      "\tval_loss : 0.4533294141292572\n",
      "val_loss: 0.4533294141292572\n",
      "step: 101\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4708576202392578\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4849914312362671\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4091622531414032\n",
      "\ttrain_loss : 0.4091622531414032\n",
      "train_loss: 0.4091622531414032\n",
      "step: 102\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4617462158203125\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48011234402656555\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4396767020225525\n",
      "\ttrain_loss : 0.4396767020225525\n",
      "train_loss: 0.4396767020225525\n",
      "step: 103\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.46726226806640625\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48307710886001587\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.421939492225647\n",
      "\ttrain_loss : 0.421939492225647\n",
      "train_loss: 0.421939492225647\n",
      "step: 104\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4649085998535156\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48181620240211487\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.42808496952056885\n",
      "\ttrain_loss : 0.42808496952056885\n",
      "train_loss: 0.42808496952056885\n",
      "step: 105\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4681205749511719\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48353540897369385\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4160395860671997\n",
      "\ttrain_loss : 0.4160395860671997\n",
      "train_loss: 0.4160395860671997\n",
      "step: 106\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4700450897216797\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4845600426197052\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4103628098964691\n",
      "\ttrain_loss : 0.4103628098964691\n",
      "train_loss: 0.4103628098964691\n",
      "step: 107\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.47424888610839844\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4867841303348541\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.3977345824241638\n",
      "\ttrain_loss : 0.3977345824241638\n",
      "train_loss: 0.3977345824241638\n",
      "step: 108\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4602622985839844\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.47930893301963806\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4411822557449341\n",
      "\ttrain_loss : 0.4411822557449341\n",
      "train_loss: 0.4411822557449341\n",
      "step: 109\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.46188926696777344\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48018965125083923\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4393179416656494\n",
      "\ttrain_loss : 0.4393179416656494\n",
      "train_loss: 0.4393179416656494\n",
      "step: 110\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.4553813934326172\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.47664880752563477\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4570077061653137\n",
      "\ttrain_loss : 0.4570077061653137\n",
      "train_loss: 0.4570077061653137\n",
      "step: 110\n",
      "out1:\n",
      "\tval_metrics:\n",
      "\t\tprecision: 0.45655736327171326\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.47729218006134033\n",
      "\tval_loss:\n",
      "\t\tbcejaccardloss: 0.4500389099121094\n",
      "\tval_loss : 0.4500389099121094\n",
      "val_loss: 0.4500389099121094\n",
      "step: 111\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.46875762939453125\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.483875036239624\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.41636961698532104\n",
      "\ttrain_loss : 0.41636961698532104\n",
      "train_loss: 0.41636961698532104\n",
      "step: 112\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.466156005859375\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48248523473739624\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4241870641708374\n",
      "\ttrain_loss : 0.4241870641708374\n",
      "train_loss: 0.4241870641708374\n",
      "step: 113\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.47269439697265625\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48596394062042236\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.40217265486717224\n",
      "\ttrain_loss : 0.40217265486717224\n",
      "train_loss: 0.40217265486717224\n",
      "step: 114\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.45316314697265625\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.47543081641197205\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.465912401676178\n",
      "\ttrain_loss : 0.465912401676178\n",
      "train_loss: 0.465912401676178\n",
      "step: 115\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.46791648864746094\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4834265112876892\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.4182090163230896\n",
      "\ttrain_loss : 0.4182090163230896\n",
      "train_loss: 0.4182090163230896\n",
      "step: 116\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.47333717346191406\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.4863033890724182\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.40085387229919434\n",
      "\ttrain_loss : 0.40085387229919434\n",
      "train_loss: 0.40085387229919434\n",
      "step: 117\n",
      "out1:\n",
      "\ttrain_metrics:\n",
      "\t\tprecision: 0.47308921813964844\n",
      "\t\trecall: 0.5\n",
      "\t\tf1: 0.48617249727249146\n",
      "\ttrain_loss:\n",
      "\t\tbcejaccardloss: 0.39786994457244873\n",
      "\ttrain_loss : 0.39786994457244873\n",
      "train_loss: 0.39786994457244873\n"
     ]
    }
   ],
   "source": [
    "best_val = -1e5\n",
    "best_metrics = None\n",
    "\n",
    "logging.info('STARTING training')\n",
    "\n",
    "for step, outputs in runner.trainer():\n",
    "    if runner.master():\n",
    "        print(f'step: {step}')\n",
    "        outputs.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "416c96f9efd8a8ffb40315f88745bb91463f1a6c2f5fa9c1c915d414fc3c9704"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('phobos': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
